/**
 * Animalese TTS Engine
 * í…ìŠ¤íŠ¸ë¥¼ ì• ë‹ˆë©€ë¦¬ì¦ˆ íš¨ê³¼ë¡œ ë³€í™˜í•˜ëŠ” ë©”ì¸ ì—”ì§„
 */

// í•œê¸€ ìëª¨ ë§¤í•‘ í…Œì´ë¸”
const CHOSEONG = ['ã„±','ã„²','ã„´','ã„·','ã„¸','ã„¹','ã…','ã…‚','ã…ƒ','ã……','ã…†','ã…‡','ã…ˆ','ã…‰','ã…Š','ã…‹','ã…Œ','ã…','ã…'];
const JUNGSEONG = ['ã…','ã…','ã…‘','ã…’','ã…“','ã…”','ã…•','ã…–','ã…—','ã…˜','ã…™','ã…š','ã…›','ã…œ','ã…','ã…','ã…Ÿ','ã… ','ã…¡','ã…¢','ã…£'];
const JONGSEONG = ['','ã„±','ã„²','ã„³','ã„´','ã„µ','ã„¶','ã„·','ã„¹','ã„º','ã„»','ã„¼','ã„½','ã„¾','ã„¿','ã…€','ã…','ã…‚','ã…„','ã……','ã…†','ã…‡','ã…ˆ','ã…Š','ã…‹','ã…Œ','ã…','ã…'];

// ìëª¨ â†’ ì•ŒíŒŒë²³ ë§¤í•‘ í…Œì´ë¸”
const JAMO_TO_ALPHA = {
    // ì´ˆì„±/ì¢…ì„± (ììŒ)
    'ã„±': 'g', 'ã„²': 'kk', 'ã„³': 'gs',
    'ã„´': 'n', 'ã„µ': 'nj', 'ã„¶': 'nh',
    'ã„·': 'd', 'ã„¸': 'dd',
    'ã„¹': 'r', 'ã„º': 'rg', 'ã„»': 'rm', 'ã„¼': 'rb', 'ã„½': 'rs', 'ã„¾': 'rt', 'ã„¿': 'rp', 'ã…€': 'rh',
    'ã…': 'm',
    'ã…‚': 'b', 'ã…ƒ': 'bb', 'ã…„': 'bs',
    'ã……': 's', 'ã…†': 'ss',
    'ã…‡': '',  // ë¬´ìŒ (ì´ˆì„±/ì¢…ì„±ì—ì„œ)
    'ã…ˆ': 'j', 'ã…‰': 'jj',
    'ã…Š': 'ch',
    'ã…‹': 'k',
    'ã…Œ': 't',
    'ã…': 'p',
    'ã…': 'h',

    // ì¤‘ì„± (ëª¨ìŒ)
    'ã…': 'a',
    'ã…': 'ae',
    'ã…‘': 'ya',
    'ã…’': 'yae',
    'ã…“': 'eo',
    'ã…”': 'e',
    'ã…•': 'yeo',
    'ã…–': 'ye',
    'ã…—': 'o',
    'ã…˜': 'wa',
    'ã…™': 'wae',
    'ã…š': 'wi',
    'ã…›': 'yo',
    'ã…œ': 'u',
    'ã…': 'wo',
    'ã…': 'we',
    'ã…Ÿ': 'wi',
    'ã… ': 'yu',
    'ã…¡': 'eu',
    'ã…¢': 'ui',
    'ã…£': 'i'
};

class TextProcessor {
    constructor() {
        this.jamoMap = JAMO_TO_ALPHA;
    }

    /**
     * í…ìŠ¤íŠ¸ë¥¼ ë¬¸ì íƒ€ì…ë³„ë¡œ íŒŒì‹±
     * @param {string} text - ì…ë ¥ í…ìŠ¤íŠ¸
     * @returns {Array} íŒŒì‹±ëœ í† í° ë°°ì—´
     */
    parse(text) {
        const result = [];
        let buffer = '';
        let type = null;

        for (const char of text) {
            const charType = this.getCharType(char);

            if (charType !== type && buffer) {
                result.push({ type, text: buffer });
                buffer = '';
                type = charType;
            }

            type = charType;
            buffer += char;
        }

        if (buffer) {
            result.push({ type, text: buffer });
        }

        return result;
    }

    /**
     * ë¬¸ìì˜ íƒ€ì…åˆ¤å®š
     * @param {string} char - ì…ë ¥ ë¬¸ì
     * @returns {string} ë¬¸ì íƒ€ì… (korean, english, number, symbol)
     */
    getCharType(char) {
        const code = char.charCodeAt(0);

        // í•œê¸€ (ìëª¨ í¬í•¨)
        if (code >= 44032 && code <= 55203) return 'korean';
        if (code >= 12593 && code <= 12643) return 'korean';

        // ì˜ì–´
        if ((code >= 65 && code <= 90) || (code >= 97 && code <= 122)) return 'english';

        // ìˆ«ì
        if (code >= 48 && code <= 57) return 'number';

        // ASCII íŠ¹ìˆ˜ë¬¸ì
        if (code <= 127) return 'symbol';

        return 'other';
    }

    /**
     * í•œê¸€ í…ìŠ¤íŠ¸ë¥¼ ìëª¨ë¡œ ë¶„ë¦¬
     * @param {string} hangul - í•œê¸€ í…ìŠ¤íŠ¸
     * @returns {Array} ìëª¨ ë°°ì—´
     */
    decomposeHangul(hangul) {
        const result = [];
        for (const char of hangul) {
            const code = char.charCodeAt(0);

            if (code >= 44032 && code <= 55203) {
                // í•œê¸€ ìŒì ˆ ë¶„í•´
                const index = code - 44032;
                const choseongIndex = Math.floor(index / (21 * 28));
                const jungseongIndex = Math.floor((index % (21 * 28)) / 28);
                const jongseongIndex = index % 28;

                if (CHOSEONG[choseongIndex]) result.push(CHOSEONG[choseongIndex]);
                if (JUNGSEONG[jungseongIndex]) result.push(JUNGSEONG[jungseongIndex]);
                if (JONGSEONG[jongseongIndex]) result.push(JONGSEONG[jongseongIndex]);
            } else if (code >= 12593 && code <= 12643) {
                // í•œê¸€ ìëª¨
                result.push(char);
            } else {
                result.push(char);
            }
        }
        return result;
    }

    /**
     * ìëª¨ë¥¼ ì˜ì–´ ì•ŒíŒŒë²³ìœ¼ë¡œ ë§¤í•‘
     * @param {string} jamo - ìëª¨ ë¬¸ì
     * @returns {string} ë§¤í•‘ëœ ì•ŒíŒŒë²³
     */
    mapJamoToAlpha(jamo) {
        return this.jamoMap[jamo] || jamo;
    }

    /**
     * í•œê¸€ í…ìŠ¤íŠ¸ë¥¼ ì•ŒíŒŒë²³ìœ¼ë¡œ ë³€í™˜
     * @param {string} koreanText - í•œê¸€ í…ìŠ¤íŠ¸
     * @returns {string} ì•ŒíŒŒë²³ ë¬¸ìì—´
     */
    processKorean(koreanText) {
        const jamo = this.decomposeHangul(koreanText);
        return jamo.map(j => this.mapJamoToAlpha(j)).join('');
    }

    /**
     * í…ìŠ¤íŠ¸ë¥¼ ì• ë‹ˆë©€ë¦¬ì¦ˆ ì‹œí€€ìŠ¤ë¡œ ë³€í™˜
     * @param {string} text - ì…ë ¥ í…ìŠ¤íŠ¸
     * @param {Object} voiceProfile - ìŒì„± í”„ë¡œí•„
     * @returns {Array} ì• ë‹ˆë©€ë¦¬ì¦ˆ ì‹œí€€ìŠ¤
     */
    textToAnimalese(text, voiceProfile) {
        const tokens = this.parse(text);
        const sequence = [];

        console.log('ğŸµ TTS ë³€í™˜ ì‹œì‘:', text);
        console.log('ğŸ›ï¸ Voice Profile:', {
            volume: voiceProfile.volume,
            pitchShift: voiceProfile.pitchShift,
            variation: voiceProfile.variation,
            intonation: voiceProfile.intonation,
            type: voiceProfile.type
        });

        for (const token of tokens) {
            let sounds = [];

            switch (token.type) {
                case 'korean':
                    // í•œê¸€: ìëª¨ ë¶„ë¦¬ â†’ ì•ŒíŒŒë²³ ë§¤í•‘
                    const alpha = this.processKorean(token.text);
                    sounds = this.alphaToSounds(alpha, voiceProfile);
                    break;

                case 'english':
                    // ì˜ì–´: ì•ŒíŒŒë²³ì„ ì§ì ‘ ë§¤í•‘
                    sounds = this.alphaToSounds(token.text.toLowerCase(), voiceProfile);
                    break;

                case 'number':
                    // ìˆ«ì: ê¸°ì¡´ ë°©ì‹ (&.0, &.1, ...)
                    sounds = this.numberToSounds(token.text, voiceProfile);
                    break;

                case 'symbol':
                    // íŠ¹ìˆ˜ë¬¸ì: SFX ì‹œìŠ¤í…œ
                    sounds = this.symbolToSounds(token.text, voiceProfile);
                    break;

                default:
                    // ê¸°íƒ€ ë¬¸ì: ê° ë¬¸ìë³„ë¡œ ì²˜ë¦¬
                    sounds = this.charToSounds(token.text, voiceProfile);
            }

            sequence.push(...sounds);
        }

        console.log('âœ… TTS ë³€í™˜ ì™„ë£Œ, ì‹œí€€ìŠ¤ ê¸¸ì´:', sequence.length);
        console.log('ğŸ“ ì²« 5ê°œ ì†Œë¦¬:', sequence.slice(0, 5));

        return sequence;
    }

    /**
     * ì•ŒíŒŒë²³ì„ ì• ë‹ˆë©€ë¦¬ì¦ˆ ì†Œë¦¬ë¡œ ë³€í™˜
     * @param {string} alpha - ì•ŒíŒŒë²³ ë¬¸ìì—´
     * @param {Object} voiceProfile - ìŒì„± í”„ë¡œí•„
     * @returns {Array} ì†Œë¦¬ ì‹œí€€ìŠ¤
     */
    alphaToSounds(alpha, voiceProfile) {
        const sounds = [];
        for (const char of alpha) {
            if (char.match(/[a-z]/)) {
                // variationì€ audio-managerì—ì„œë§Œ ì ìš© (ì¤‘ë³µ ë°©ì§€)
                const pitchVariation = this.getCharPitch(char);

                sounds.push({
                    path: `&.${char}`,
                    duration: this.getCharDuration(char),
                    volume: voiceProfile.volume || 0.65,
                    pitchShift: (voiceProfile.pitchShift || 0) + pitchVariation,
                    variation: voiceProfile.variation || 0,  // variation ê°’ì„ audio-managerì— ì „ë‹¬
                    intonation: voiceProfile.intonation || 0,
                    rate: 1.0,
                    type: voiceProfile.type || 'f1'  // ìŒì„± íƒ€ì… ì¶”ê°€
                });
            }
        }
        return sounds;
    }

    /**
     * ìˆ«ìë¥¼ ì• ë‹ˆë©€ë¦¬ì¦ˆ ì†Œë¦¬ë¡œ ë³€í™˜
     * @param {string} number - ìˆ«ì ë¬¸ìì—´
     * @param {Object} voiceProfile - ìŒì„± í”„ë¡œí•„
     * @returns {Array} ì†Œë¦¬ ì‹œí€€ìŠ¤
     */
    numberToSounds(number, voiceProfile) {
        const sounds = [];
        for (const digit of number) {
            sounds.push({
                path: `&.${digit}`,
                duration: this.getCharDuration(digit),
                volume: voiceProfile.volume || 0.65,
                pitchShift: (voiceProfile.pitchShift || 0),
                variation: voiceProfile.variation || 0,
                intonation: voiceProfile.intonation || 0,
                rate: 1.0,
                type: voiceProfile.type || 'f1'  // ìŒì„± íƒ€ì… ì¶”ê°€
            });
        }
        return sounds;
    }

    /**
     * íŠ¹ìˆ˜ë¬¸ìë¥¼ SFXë¡œ ë³€í™˜
     * @param {string} symbol - íŠ¹ìˆ˜ë¬¸ì
     * @param {Object} voiceProfile - ìŒì„± í”„ë¡œí•„
     * @returns {Array} ì†Œë¦¬ ì‹œí€€ìŠ¤
     */
    /**
     * SFX ë²„íŠ¼ ìƒíƒœ í™•ì¸
     * @returns {boolean} SFXê°€ í™œì„±í™”ë˜ì–´ ìˆëŠ”ì§€ ì—¬ë¶€
     */
    isSFXEnabled() {
        const sfxButton = document.getElementById('sfx_button');
        if (!sfxButton) return true; // ë²„íŠ¼ì´ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ true
        return sfxButton.getAttribute('pressed') === 'true';
    }

    symbolToSounds(symbol, voiceProfile) {
        // SFX ë²„íŠ¼ì´ ë¹„í™œì„±í™”ë˜ì–´ ìˆìœ¼ë©´ ë¹ˆ ë°°ì—´ ë°˜í™˜
        if (!this.isSFXEnabled()) {
            return [];
        }

        const sounds = [];
        const sfxMap = {
            ' ': { path: 'sfx.space', duration: 150 },
            '!': { path: 'sfx.exclamation', duration: 200 },
            '?': { path: 'sfx.question', duration: 200 },
            '.': { path: 'sfx.period', duration: 200 },
            ',': { path: 'sfx.comma', duration: 150 },
            '\n': { path: 'sfx.enter', duration: 250 }
        };

        for (const char of symbol) {
            const sfx = sfxMap[char];
            if (sfx) {
                sounds.push({
                    ...sfx,
                    volume: voiceProfile.volume || 0.65,
                    pitchShift: voiceProfile.pitchShift || 0,
                    variation: voiceProfile.variation || 0,
                    intonation: voiceProfile.intonation || 0,
                    rate: 1.0,
                    type: voiceProfile.type || 'f1'  // ìŒì„± íƒ€ì… ì¶”ê°€
                });
            }
        }
        return sounds;
    }

    /**
     * ë¬¸ìë¥¼ ê°œë³„ì ìœ¼ë¡œ ì²˜ë¦¬
     * @param {string} char - ë¬¸ì
     * @param {Object} voiceProfile - ìŒì„± í”„ë¡œí•„
     * @returns {Array} ì†Œë¦¬ ì‹œí€€ìŠ¤
     */
    charToSounds(char, voiceProfile) {
        if (char === ' ') {
            // SFX ë²„íŠ¼ì´ ë¹„í™œì„±í™”ë˜ì–´ ìˆìœ¼ë©´ ë¹ˆ ë°°ì—´ ë°˜í™˜
            if (!this.isSFXEnabled()) {
                return [];
            }
            return [{ path: 'sfx.space', duration: 150, volume: voiceProfile.volume || 0.65, pitchShift: voiceProfile.pitchShift || 0, variation: voiceProfile.variation || 0, intonation: voiceProfile.intonation || 0, rate: 1.0, type: voiceProfile.type || 'f1' }];
        }
        return [];
    }

    /**
     * ë¬¸ìì˜ ì§€ì† ì‹œê°„ ê³„ì‚°
     * @param {string} char - ë¬¸ì
     * @returns {number} ì§€ì† ì‹œê°„ (ms)
     */
    getCharDuration(char) {
        // ëª¨ìŒì€ ë” ê¸¸ê²Œ, ììŒì€ ë” ì§§ê²Œ
        const vowels = 'aeiouy';
        const durationMap = {
            'a': 120, 'e': 110, 'i': 100, 'o': 115, 'u': 105,
            'b': 80, 'c': 85, 'd': 85, 'f': 80, 'g': 80,
            'h': 90, 'j': 75, 'k': 80, 'l': 85, 'm': 85,
            'n': 85, 'p': 80, 'q': 80, 'r': 90, 's': 85,
            't': 85, 'v': 80, 'w': 100, 'x': 85, 'y': 100, 'z': 85
        };
        return durationMap[char] || 90;
    }

    /**
     * ë¬¸ìì˜ í”¼ì¹˜ ê³„ì‚°
     * @param {string} char - ë¬¸ì
     * @returns {number} í”¼ì¹˜ ê°’
     */
    getCharPitch(char) {
        // ë¬¸ìì— ë”°ë¥¸ í”¼ì¹˜ ë³€í™” (ì•½ê°„ì˜ ë³€ì£¼)
        const pitchMap = {
            'a': 0.5, 'e': 0.3, 'i': 0.8, 'o': 0.4, 'u': 0.6,
            'b': -0.2, 'c': 0, 'd': 0, 'f': -0.1, 'g': -0.1,
            'h': 0.1, 'j': 0.2, 'k': 0, 'l': 0.1, 'm': -0.1,
            'n': 0, 'p': -0.2, 'q': 0, 'r': 0.2, 's': 0,
            't': 0, 'v': 0, 'w': 0.3, 'x': 0, 'y': 0.4, 'z': 0
        };
        return pitchMap[char] || 0;
    }
}

class WaveRecorder {
    constructor(audioManager) {
        this.audioManager = audioManager;
    }

    /**
     * Howler ì´ˆê¸°í™” ë³´ì¥ (ìŒì†Œê±°çŠ¶æ€ä¸‹ í…ŒìŠ¤íŠ¸ ì‚¬ìš´ë“œ ì¬ìƒ)
     * Howler.ctxì´ ì œëŒ€ë¡œ ì´ˆê¸°í™”ë˜ì§€ ì•Šì€ ê²½ìš°, ìŒì†Œê±°ëœ ì‚¬ìš´ë“œë¥¼ ì¬ìƒí•˜ì—¬ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.
     *
     * @returns {Promise<boolean>} ì´ˆê¸°í™” ì„±ê³µ ì—¬ë¶€
     */
    async ensureHowlerInitialized() {
        console.log('\n=== Howler ì´ˆê¸°í™” ë³´ì¥ ===');

        try {
            // í˜„ì¬ AudioContext ìƒíƒœ í™•ì¸
            const ctx = this.audioManager.getAudioContext();
            console.log('í˜„ì¬ AudioContext:', ctx);
            console.log('AudioContext ìƒíƒœ:', ctx.state);

            // AudioContextê°€ suspendedì´ë©´ resume
            if (ctx.state !== 'running') {
                console.log('AudioContext resume ì‹œë„...');
                await ctx.resume();
                console.log('AudioContext resumeë¨, ìƒˆ ìƒíƒœ:', ctx.state);
            }

            // Howler._sounds ë°°ì—´ í™•ì¸
            if (typeof Howler !== 'undefined' && Howler._sounds) {
                console.log('Howler._sounds ì¡´ì¬:', Howler._sounds.length, 'ê°œ ì‚¬ìš´ë“œ');
            }

            // Howler.ctxê°€ ì—¬ì „íˆ ë¹ˆ ê°ì²´ì´ë©´ í…ŒìŠ¤íŠ¸ ì‚¬ìš´ë“œ ì¬ìƒ
            if (Object.keys(ctx).length === 0) {
                console.warn('Howler.ctxì´ ë¹ˆ ê°ì²´ì…ë‹ˆë‹¤. í…ŒìŠ¤íŠ¸ ì‚¬ìš´ë“œ ì¬ìƒí•˜ì—¬ ì´ˆê¸°í™” ì‹œë„...');

                // ìŒì†Œê±°ëœ ì‚¬ìš´ë“œ ì¬ìƒ (0 ë³¼ë¥¨)
                this.audioManager.play('&.a', { volume: 0, noRandom: true });

                // ì ì‹œ ëŒ€ê¸°
                await new Promise(resolve => setTimeout(resolve, 100));

                // ë‹¤ì‹œ AudioContext í™•ì¸
                const newCtx = this.audioManager.getAudioContext();
                console.log('í…ŒìŠ¤íŠ¸ í›„ AudioContext:', newCtx);
                console.log('ìƒˆ AudioContext ìƒíƒœ:', newCtx.state);

                if (Object.keys(newCtx).length === 0) {
                    console.error('AudioContextê°€ ì—¬ì „íˆ ë¹ˆ ê°ì²´ì…ë‹ˆë‹¤');
                    return false;
                }
            }

            console.log('âœ… Howler ì´ˆê¸°í™” í™•ì¸ë¨\n');
            return true;
        } catch (error) {
            console.error('Howler ì´ˆê¸°í™” ì‹¤íŒ¨:', error);
            return false;
        }
    }

    /**
     * ì˜¤ë””ì˜¤ ìº¡ì²˜ ì—°ê²° í…ŒìŠ¤íŠ¸
     * ì—°ê²°ì´ ì •ìƒì ìœ¼ë¡œ ì‘ë™í•˜ëŠ”ì§€ ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.
     *
     * @returns {Promise<boolean>} ì—°ê²° ì„±ê³µ ì—¬ë¶€
     */
    async testAudioCapture() {
        console.log('\n=== ì˜¤ë””ì˜¤ ìº¡ì²˜ ì—°ê²° í…ŒìŠ¤íŠ¸ ===');

        try {
            const audioContext = this.audioManager.getAudioContext();
            if (!audioContext || !audioContext.createMediaStreamDestination) {
                console.error('AudioContext ë˜ëŠ” MediaStreamDestination ì§€ì› ì•ˆ í•¨');
                return false;
            }

            const destination = audioContext.createMediaStreamDestination();
            console.log('MediaStreamDestination ìƒì„±ë¨');

            // ë¹ˆ ì†Œë¦¬ ì¬ìƒìœ¼ë¡œ ì—°ê²° í…ŒìŠ¤íŠ¸
            this.audioManager.connectToRecorder(destination);

            // ì ì‹œ ëŒ€ê¸° í›„ ì—°ê²° ìƒíƒœ í™•ì¸
            await new Promise(resolve => setTimeout(resolve, 200));

            const track = destination.stream.getAudioTracks()[0];
            if (!track) {
                console.error('AudioTrackì„ ì°¾ì„ ìˆ˜ ì—†ìŒ');
                return false;
            }

            console.log('âœ“ AudioTrack ë°œê²¬:', {
                enabled: track.enabled,
                muted: track.muted,
                readyState: track.readyState
            });

            console.log('=== í…ŒìŠ¤íŠ¸ ì™„ë£Œ: ì„±ê³µ ===\n');
            return true;
        } catch (error) {
            console.error('=== í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨:', error.message, '===\n');
            return false;
        }
    }

    /**
     * ìŒì„± ì‹œí€€ìŠ¤ë¥¼ WAVë¡œ ë³€í™˜ (ì›ë³¸ íŒŒì¼ ê¸°ë°˜)
     *
     * MediaRecorder ëŒ€ì‹  ì›ë³¸ ì˜¤ë””ì˜¤ íŒŒì¼ë“¤ì„ ffmpegë¡œ ì§ì ‘ ë³€í™˜í•©ë‹ˆë‹¤.
     * ë” ì•ˆì •ì ì´ê³  Electron í™˜ê²½ì—ì„œë„ ì‘ë™í•©ë‹ˆë‹¤.
     *
     * @param {Array} soundSequence - ìŒì„± ì‹œí€€ìŠ¤
     * @param {Object} options - ì˜µì…˜ (quality ë“±)
     * @returns {Promise<Blob>} WAV Blob
     */
    async recordSequence(soundSequence, options = {}) {
        console.log('\n========================================');
        console.log('=== ì›ë³¸ íŒŒì¼ ê¸°ë°˜ ë³€í™˜ ì‹œì‘ ===');
        console.log('========================================');
        console.log('ì‹œí€€ìŠ¤ ê¸¸ì´:', soundSequence.length);
        console.log('ì˜µì…˜:', options);

        const quality = options.quality || 'low';
        const playbackRate = options.playbackRate || 1.0;
        let voiceProfile = options.voiceProfile || { type: 'f1', pitchShift: 0, variation: 0, intonation: 0 };

        // ìŒì„±í”„ë¡œí•„ì´ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ ì‚¬ìš© (ê°•ì œ ì ìš©)
        if (!voiceProfile) {
            console.warn('âš ï¸ voiceProfileì´ undefinedì…ë‹ˆë‹¤. ê¸°ë³¸ê°’ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.');
            voiceProfile = { type: 'f1', pitchShift: 0, variation: 0, intonation: 0 };
        }

        try {
            // ìŒì„± ì‹œí€€ìŠ¤ë¥¼ ì˜¤ë””ì˜¤ íŒŒì¼ ëª©ë¡ìœ¼ë¡œ ë³€í™˜
            const audioFiles = this.sequenceToAudioFiles(soundSequence, voiceProfile);
            console.log('ë³€í™˜ëœ ì˜¤ë””ì˜¤ íŒŒì¼ ëª©ë¡:', audioFiles);

            // ffmpegë¡œ ì˜¤ë””ì˜¤ íŒŒì¼ë“¤ì„ í•˜ë‚˜ì˜ WAVë¡œ ë³€í™˜
            const wavBlob = await this.convertAudioFilesToWav(audioFiles, quality, playbackRate, voiceProfile);
            console.log('\n========================================');
            console.log('=== ë³€í™˜ ì„±ê³µ ===');
            console.log('========================================\n');
            return wavBlob;
        } catch (error) {
            console.error('ë³€í™˜ ì‹¤íŒ¨:', error);
            throw new Error(`ì˜¤ë””ì˜¤ ë³€í™˜ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: ${error.message}`);
        }
    }

    /**
     * ìŒì„± ì‹œí€€ìŠ¤ì—ì„œ ìŒì„±í”„ë¡œí•„ ì •ë³´ ì¶”ì¶œ
     * @param {Array} audioFiles - ì˜¤ë””ì˜¤ íŒŒì¼ ì •ë³´ ë°°ì—´
     * @returns {Object} ìŒì„± í”„ë¡œí•„ ì •ë³´
     */
    extractVoiceProfileFromSequence(audioFiles) {
        // audioFilesì—ëŠ” ìŒì„±í”„ë¡œí•„ ì •ë³´ê°€ ì—†ìœ¼ë¯€ë¡œ ê¸°ë³¸ê°’ ë°˜í™˜
        // ì‹¤ì œ ê°’ì€ voiceProfile íŒŒë¼ë¯¸í„°ë¡œ ì „ë‹¬ë°›ìŒ
        return {
            type: 'f1',
            pitchShift: 0,
            variation: 0,
            intonation: 0
        };
    }

    /**
     * ìŒì„± ì‹œí€€ìŠ¤ë¥¼ ì˜¤ë””ì˜¤ íŒŒì¼ ëª©ë¡ìœ¼ë¡œ ë³€í™˜
     * @param {Array} soundSequence - ìŒì„± ì‹œí€€ìŠ¤
     * @param {Object} voiceProfile - ìŒì„± í”„ë¡œí•„ (type í¬í•¨)
     * @returns {Array} ì˜¤ë””ì˜¤ íŒŒì¼ ì •ë³´ ë°°ì—´
     */
    sequenceToAudioFiles(soundSequence, voiceProfile) {
        const audioFiles = [];
        const voiceType = voiceProfile?.type || 'f1';

        for (const sound of soundSequence) {
            // ìŒì„± ê²½ë¡œë¥¼ íŒŒì¼ ì •ë³´ë¡œ ë³€í™˜ (voiceType í¬í•¨)
            const fileInfo = this.soundPathToFileInfo(sound.path, voiceType);
            if (fileInfo) {
                audioFiles.push({
                    path: fileInfo.filePath,
                    offset: fileInfo.offset,
                    duration: fileInfo.duration,
                    soundDuration: sound.duration / 1000 // seconds
                });
            }
        }

        // ìµœì í™”: ë™ì¼í•œ íŒŒì¼ ê²½ë¡œ, ì˜¤í”„ì…‹, durationì„ ê°€ì§„ ì—°ì†ëœ ì„¸ê·¸ë¨¼íŠ¸ë“¤ì„ í•©ì¹˜ê¸°
        const optimizedFiles = this.optimizeAudioFiles(audioFiles);
        return optimizedFiles;
    }

    /**
     * ì—°ì†ëœ ë™ì¼ ì„¸ê·¸ë¨¼íŠ¸ë“¤ì„ í•˜ë‚˜ë¡œ í•©ì¹˜ê¸° (ìµœì í™”)
     * @param {Array} audioFiles - ì˜¤ë””ì˜¤ íŒŒì¼ ì •ë³´ ë°°ì—´
     * @returns {Array} ìµœì í™”ëœ ì˜¤ë””ì˜¤ íŒŒì¼ ì •ë³´ ë°°ì—´
     */
    optimizeAudioFiles(audioFiles) {
        if (audioFiles.length === 0) return audioFiles;

        // ìµœì í™” ë¹„í™œì„±í™” - ffmpegì—ì„œ ì„¸ê·¸ë¨¼íŠ¸ í•©ì¹˜ê¸° ë¬¸ì œê°€ ìˆì–´ ì„ì‹œ ë¹„í™œì„±í™”
        // TODO: ì¶”í›„ ìµœì í™” ë¡œì§ ê°œì„  í•„ìš”
        return audioFiles;

        /* ì´ì „ ìµœì í™” ë¡œì§ (ë¬¸ì œ ìˆìŒ - ë¹„í™œì„±í™”)
        const optimized = [];
        let current = { ...audioFiles[0] };

        for (let i = 1; i < audioFiles.length; i++) {
            const next = audioFiles[i];

            // í˜„ì¬ì™€ ë‹¤ìŒì´ ë™ì¼í•˜ê³  ì—°ì†ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
            if (
                current.path === next.path &&
                current.offset === next.offset &&
                current.duration === next.duration
            ) {
                // ì—°ì†ëœ ë™ì¼ ì„¸ê·¸ë¨¼íŠ¸ë¥¼ í•˜ë‚˜ë¡œ í•©ì¹˜ê¸°
                current.soundDuration += next.soundDuration;
            } else {
                // ë‹¤ë¥´ë©´ í˜„ì¬ ì„¸ê·¸ë¨¼íŠ¸ë¥¼ ì €ì¥í•˜ê³  ìƒˆë¡œìš´ ì„¸ê·¸ë¨¼íŠ¸ ì‹œì‘
                optimized.push(current);
                current = { ...next };
            }
        }

        // ë§ˆì§€ë§‰ ì„¸ê·¸ë¨¼íŠ¸ ì¶”ê°€
        optimized.push(current);

        return optimized;
        */
    }

    /**
     * ìŒì„± ê²½ë¡œë¥¼ ì‹¤ì œ íŒŒì¼ ì •ë³´ë¡œ ë³€í™˜
     * @param {string} soundPath - ìŒì„± ê²½ë¡œ (ì˜ˆ: "&.a", "sfx.enter")
     * @param {string} voiceType - ìŒì„± íƒ€ì… (ì˜ˆ: "f1", "m1")
     * @returns {Object|null} íŒŒì¼ ì •ë³´ { filePath, offset, duration }
     */
    soundPathToFileInfo(soundPath, voiceType = 'f1') {
        // voice_sprite ì •ë³´ (audio-manager.cjsì—ì„œ ê°€ì ¸ì˜´)
        const voice_sprite = {
            'a': [200 * 0, 200], 'b': [200 * 1, 200], 'c': [200 * 2, 200], 'd': [200 * 3, 200],
            'e': [200 * 4, 200], 'f': [200 * 5, 200], 'g': [200 * 6, 200], 'h': [200 * 7, 200],
            'i': [200 * 8, 200], 'j': [200 * 9, 200], 'k': [200 * 10, 200], 'l': [200 * 11, 200],
            'm': [200 * 12, 200], 'n': [200 * 13, 200], 'o': [200 * 14, 200], 'p': [200 * 15, 200],
            'q': [200 * 16, 200], 'r': [200 * 17, 200], 's': [200 * 18, 200], 't': [200 * 19, 200],
            'u': [200 * 20, 200], 'v': [200 * 21, 200], 'w': [200 * 22, 200], 'x': [200 * 23, 200],
            'y': [200 * 24, 200], 'z': [200 * 25, 200],
            '1': [200 * 26, 200], '2': [200 * 27, 200], '3': [200 * 28, 200], '4': [200 * 29, 200],
            '5': [200 * 30, 200], '6': [200 * 31, 200], '7': [200 * 32, 200], '8': [200 * 33, 200],
            '9': [200 * 34, 200], '0': [200 * 35, 200]
        };

        // sfx_sprite ì •ë³´
        const sfx_sprite = {
            'backspace': [600 * 0, 600], 'enter': [600 * 1, 600], 'tab': [600 * 2, 600],
            'question': [600 * 3, 600], 'exclamation': [600 * 4, 600],
            'space': [600 * 5, 600], 'period': [600 * 6, 600], 'comma': [600 * 7, 600],
            'at': [600 * 8, 600], 'pound': [600 * 9, 600], 'dollar': [600 * 10, 600],
            'caret': [600 * 11, 600], 'ampersand': [600 * 12, 600], 'asterisk': [600 * 13, 600]
        };

        console.log('ìŒì„± ê²½ë¡œ íŒŒì‹±:', soundPath);

        // íŒ¨í„´ 1: &.char (ì˜ˆ: &.a, &.b, &.z)
        const andMatch = soundPath.match(/^\&\.([a-z0-9]+)$/);
        if (andMatch) {
            const [, char] = andMatch;
            const sprite = voice_sprite[char];
            if (sprite) {
                // voice profileì—ì„œ ê°€ì ¸ì˜¨ voiceType ì‚¬ìš©
                return {
                    filePath: `voice/${voiceType}.ogg`,
                    offset: sprite[0] / 1000, // ms to seconds
                    duration: sprite[1] / 1000 // ms to seconds
                };
            }
        }

        // íŒ¨í„´ 2: voiceType.char (ì˜ˆ: f1.a, m2.z)
        const voiceMatch = soundPath.match(/^([fm]\d)\.([a-z0-9]+)$/);
        if (voiceMatch) {
            const [, voiceType, char] = voiceMatch;
            const sprite = voice_sprite[char];
            if (sprite) {
                return {
                    filePath: `voice/${voiceType}.ogg`,
                    offset: sprite[0] / 1000,
                    duration: sprite[1] / 1000
                };
            }
        }

        // íŒ¨í„´ 3: sfx.soundname
        const sfxMatch = soundPath.match(/^sfx\.([a-z]+)$/);
        if (sfxMatch) {
            const [, soundName] = sfxMatch;
            const sprite = sfx_sprite[soundName];
            if (sprite) {
                return {
                    filePath: 'sfx.ogg',
                    offset: sprite[0] / 1000,
                    duration: sprite[1] / 1000
                };
            }
        }

        console.warn(`ì•Œ ìˆ˜ ì—†ëŠ” ìŒì„± ê²½ë¡œ: ${soundPath}`);
        return null;
    }

    /**
     * ì˜¤ë””ì˜¤ íŒŒì¼ ëª©ë¡ì„ ffmpegë¡œ WAVë¡œ ë³€í™˜
     * @param {Array} audioFiles - ì˜¤ë””ì˜¤ íŒŒì¼ ì •ë³´ ëª©ë¡
     * @param {string} quality - í’ˆì§ˆ ì„¤ì •
     * @param {number} playbackRate - ì¬ìƒ ì†ë„ (atempo í•„í„°ìš©)
     * @param {Object} voiceProfile - ìŒì„± í”„ë¡œí•„ (pitch, variation, intonation í¬í•¨)
     * @returns {Promise<Blob>} WAV Blob
     */
    async convertAudioFilesToWav(audioFiles, quality, playbackRate = 1.0, voiceProfile = { type: 'f1', pitchShift: 0, variation: 0, intonation: 0 }) {
        console.log('ffmpeg ë³€í™˜ ì‹œì‘:', audioFiles.length, 'ê°œ ì„¸ê·¸ë¨¼íŠ¸');
        console.log('ì¬ìƒ ì†ë„:', playbackRate);
        console.log('ìŒì„± í”„ë¡œí•„:', voiceProfile);

        // ê° íŒŒì¼ì—ì„œ í•„ìš”í•œ ë¶€ë¶„ë§Œ ì¶”ì¶œí•˜ì—¬ concat
        return this.extractAndConcatSegments(audioFiles, quality, playbackRate, voiceProfile);
    }

    /**
     * ì˜¤ë””ì˜¤ ì„¸ê·¸ë¨¼íŠ¸ë“¤ì„ ì¶”ì¶œí•˜ì—¬ concat í›„ WAVë¡œ ë³€í™˜
     * IPCë¥¼ í†µí•´ ë©”ì¸ í”„ë¡œì„¸ìŠ¤ì˜ ffmpegë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤.
     *
     * @param {Array} audioFiles - ì˜¤ë””ì˜¤ íŒŒì¼ ì •ë³´ ëª©ë¡
     * @param {string} quality - í’ˆì§ˆ ì„¤ì •
     * @param {number} playbackRate - ì¬ìƒ ì†ë„ (atempo í•„í„°ìš©)
     * @returns {Promise<Blob>} WAV Blob
     */
    async extractAndConcatSegments(audioFiles, quality, playbackRate = 1.0, voiceProfile) {
        console.log('IPC ë³€í™˜ ìš”ì²­:', audioFiles.length, 'ê°œ ì„¸ê·¸ë¨¼íŠ¸');
        console.log('ì „ì†¡í•  ì¬ìƒ ì†ë„ (atempo):', playbackRate);

        // ìŒì„±í”„ë¡œí•„ì´ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ ì‚¬ìš© (ê°•ì œ ì ìš©)
        if (!voiceProfile) {
            console.warn('âš ï¸ voiceProfileì´ undefinedì…ë‹ˆë‹¤. ê¸°ë³¸ê°’ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.');
            voiceProfile = { type: 'f1', pitchShift: 0, variation: 0, intonation: 0 };
        }

        console.log('ì „ì†¡í•  ìŒì„± í”„ë¡œí•„:', voiceProfile);

        // IPCë¥¼ í†µí•´ ë©”ì¸ í”„ë¡œì„¸ìŠ¤ì˜ ffmpeg ë³€í™˜ í˜¸ì¶œ
        const result = await window.api.convertTtsToWav(audioFiles, quality, playbackRate, voiceProfile);

        if (!result.success) {
            throw new Error(result.error);
        }

        console.log('IPC ë³€í™˜ ì„±ê³µ, ë°ì´í„° í¬ê¸°:', result.data.length);

        // Base64ë¡œ ì¸ì½”ë”©ëœ WAV ë°ì´í„°ë¥¼ Blobìœ¼ë¡œ ë³€í™˜
        const binaryString = atob(result.data);
        const bytes = new Uint8Array(binaryString.length);
        for (let i = 0; i < binaryString.length; i++) {
            bytes[i] = binaryString.charCodeAt(i);
        }
        const wavBlob = new Blob([bytes], { type: result.mimeType });

        return wavBlob;
    }


    /**
     * ë…¹ìŒ ì‹œë„ (ë‚´ë¶€ í•¨ìˆ˜)
     * @private
     */

    /**
     * ì§€ì›ë˜ëŠ” MIME íƒ€ì… í™•ì¸
     * @returns {string} MIME íƒ€ì…
     */
    getSupportedMimeType() {
        const types = [
            'audio/webm;codecs=opus',
            'audio/webm',
            'audio/ogg;codecs=opus',
            'audio/ogg',
            'audio/mp4'  // Fallback ì¶”ê°€
        ];

        console.log('MediaRecorder ì§€ì› MIME íƒ€ì… í™•ì¸...');
        for (const type of types) {
            if (MediaRecorder.isTypeSupported(type)) {
                console.log(`ì§€ì›ë¨: ${type}`);
                return type;
            }
        }

        console.warn('ì§€ì›ë˜ëŠ” MIME íƒ€ì…ì´ ì—†ìŒ, ê¸°ë³¸ê°’ ì‚¬ìš©');
        return ''; // ê¸°ë³¸ê°’ ì‚¬ìš©
    }

    /**
     * ìŒì„± ì‹œí€€ìŠ¤ ì¬ìƒ
     * @param {Array} soundSequence - ìŒì„± ì‹œí€€ìŠ¤
     * @returns {Promise<number>} ì´ ì§€ì† ì‹œê°„
     */
    async playSequence(soundSequence) {
        return new Promise((resolve) => {
            let currentIndex = 0;
            let totalDuration = 0;

            const playNext = () => {
                if (currentIndex >= soundSequence.length) {
                    resolve(totalDuration);
                    return;
                }

                const sound = soundSequence[currentIndex];
                totalDuration += sound.duration;

                console.log(`\nğŸ”Š Playing sound #${currentIndex + 1}/${soundSequence.length}:`);
                console.log('  Path:', sound.path);
                console.log('  Duration:', sound.duration, 'ms');
                console.log('  Volume:', sound.volume || 0.65);
                console.log('  Pitch:', sound.pitchShift || 0);
                console.log('  Variation:', sound.pitchVariation || 0);
                console.log('  Intonation:', sound.intonation || 0);
                console.log('  Rate:', sound.rate || 1.0);
                console.log('  Type:', sound.type || 'f1');

                this.audioManager.play(sound.path, {
                    volume: sound.volume || 0.65,
                    pitchShift: sound.pitchShift || 0,
                    pitchVariation: sound.variation || 0,
                    intonation: sound.intonation || 0,
                    rate: sound.rate || 1.0,
                    type: sound.type || 'f1'
                });

                console.log(`âœ“ Sound #${currentIndex + 1} playback initiated`);

                currentIndex++;
                setTimeout(playNext, sound.duration);
            };

            playNext();
        });
    }

    /**
     * WebM/OGGë¥¼ WAVë¡œ ë³€í™˜
     * @param {Blob} audioBlob - ì…ë ¥ ì˜¤ë””ì˜¤ Blob
     * @param {string} quality - í’ˆì§ˆ ì„¤ì •
     * @returns {Promise<Blob>} WAV Blob
     */
    /**
     * WebM/oggë¥¼ WAVë¡œ ë³€í™˜
     *
     * WebAudio ê¸°ë°˜ í™˜ê²½ì—ì„œëŠ” AudioContext.decodeAudioDataë¥¼,
     * Node/Electron í™˜ê²½ì—ì„œëŠ” FFmpegë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
     *
     * @param {Blob} audioBlob - ë³€í™˜í•  ì˜¤ë””ì˜¤ Blob (WebM, OGG ë“±)
     * @param {string} quality - í’ˆì§ˆ ('low', 'standard', 'high')
     * @returns {Promise<Blob>} WAV Blob
     */
    /**
     * NOTE: convertToWav functions have been removed.
     * All conversions now use IPC-based file conversion.
     */

    /**
     * í’ˆì§ˆ ì„¤ì • ë°˜í™˜
     * @param {string} quality - í’ˆì§ˆ ('low', 'standard', 'high')
     * @returns {Object} WAV ì„¤ì •
     */
    getWavConfig(quality) {
        switch (quality) {
            case 'high':
                return { sampleRate: 48000, bitDepth: 24, channels: 1 };
            case 'standard':
                return { sampleRate: 44100, bitDepth: 16, channels: 1 };
            case 'low':
            default:
                return { sampleRate: 22050, bitDepth: 8, channels: 1 };
        }
    }

    /**
     * AudioBufferë¥¼ WAVë¡œ ì¸ì½”ë”©
     * @param {AudioBuffer} audioBuffer - AudioBuffer
     * @param {Object} config - WAV ì„¤ì •
     * @returns {Blob} WAV Blob
     */
    encodeWav(audioBuffer, config) {
        const length = audioBuffer.length;
        const bytesPerSample = config.bitDepth / 8;
        const blockAlign = config.channels * bytesPerSample;
        const byteRate = config.sampleRate * blockAlign;

        const arrayBuffer = new ArrayBuffer(44 + length * bytesPerSample);
        const view = new DataView(arrayBuffer);

        // WAV í—¤ë” ì‘ì„±
        this.writeString(view, 0, 'RIFF');
        view.setUint32(4, 36 + length * bytesPerSample, true);
        this.writeString(view, 8, 'WAVE');
        this.writeString(view, 12, 'fmt ');
        view.setUint32(16, 16, true);
        view.setUint16(20, 1, true);
        view.setUint16(22, config.channels, true);
        view.setUint32(24, config.sampleRate, true);
        view.setUint32(28, byteRate, true);
        view.setUint16(32, blockAlign, true);
        view.setUint16(34, config.bitDepth, true);
        this.writeString(view, 36, 'data');
        view.setUint32(40, length * bytesPerSample, true);

        // PCM ë°ì´í„° ì‘ì„±
        const channelData = audioBuffer.getChannelData(0);
        let offset = 44;

        for (let i = 0; i < length; i++) {
            const sample = this.convertSample(channelData[i], config.bitDepth);
            if (config.bitDepth === 8) {
                view.setUint8(offset, sample);
                offset += 1;
            } else if (config.bitDepth === 16) {
                view.setInt16(offset, sample, true);
                offset += 2;
            } else if (config.bitDepth === 24) {
                // 24bitëŠ” íŠ¹ë³„í•œ ì²˜ë¦¬ í•„ìš”
                const int24 = sample >> 8;
                view.setUint8(offset, int24 & 0xFF);
                view.setUint8(offset + 1, (int24 >> 8) & 0xFF);
                view.setUint8(offset + 2, (int24 >> 16) & 0xFF);
                offset += 3;
            }
        }

        return new Blob([arrayBuffer], { type: 'audio/wav' });
    }

    /**
     * ìƒ˜í”Œ ê°’ ë³€í™˜
     * @param {number} sample - ì •ê·œí™”ëœ ìƒ˜í”Œ (-1.0 ~ 1.0)
     * @param {number} bitDepth - ë¹„íŠ¸ ì‹¬ë„
     * @returns {number} ë³€í™˜ëœ ìƒ˜í”Œ ê°’
     */
    convertSample(sample, bitDepth) {
        // í´ë¦¬í•‘ ë°©ì§€
        sample = Math.max(-1, Math.min(1, sample));

        if (bitDepth === 8) {
            // 8bit: 0 ~ 255 (unsigned)
            return Math.floor((sample + 1) * 127.5);
        } else if (bitDepth === 16) {
            // 16bit: -32768 ~ 32767 (signed)
            return Math.floor(sample * 32767);
        } else if (bitDepth === 24) {
            // 24bit: -8388608 ~ 8388607 (signed)
            return Math.floor(sample * 8388607);
        }

        return 0;
    }

    /**
     * ë¬¸ìì—´ì„ DataViewì— ì“°ê¸°
     * @param {DataView} view - DataView
     * @param {number} offset - ì˜¤í”„ì…‹
     * @param {string} string - ë¬¸ìì—´
     */
    writeString(view, offset, string) {
        for (let i = 0; i < string.length; i++) {
            view.setUint8(offset + i, string.charCodeAt(i));
        }
    }
}

class TTSEngine {
    constructor(audioManager) {
        this.audioManager = audioManager;
        this.textProcessor = new TextProcessor();
        this.waveRecorder = new WaveRecorder(audioManager);
    }

    /**
     * SRT íŒŒì¼ íŒŒì‹±
     * @param {string} srtContent - SRT íŒŒì¼ ë‚´ìš©
     * @returns {Array} íŒŒì‹±ëœ cue ë°°ì—´
     */
    parseSRT(srtContent) {
        const cues = [];
        const blocks = srtContent.trim().split(/\n\s*\n/);

        for (const block of blocks) {
            const lines = block.trim().split('\n');
            if (lines.length >= 3) {
                const index = parseInt(lines[0]);
                const timeLine = lines[1];
                const text = lines.slice(2).join('\n');

                const match = timeLine.match(/(\d{2}):(\d{2}):(\d{2}),(\d{3})\s*-->\s*(\d{2}):(\d{2}):(\d{2}),(\d{3})/);
                if (match) {
                    const startTime = this.timeToMs(match[1], match[2], match[3], match[4]);
                    const endTime = this.timeToMs(match[5], match[6], match[7], match[8]);

                    cues.push({
                        index,
                        startTime,
                        endTime,
                        duration: endTime - startTime,
                        text
                    });
                }
            }
        }

        return cues;
    }

    /**
     * ì‹œê°„ ë¬¸ìì—´ì„ ë°€ë¦¬ì´ˆë¡œ ë³€í™˜
     * @param {string} hh - ì‹œ
     * @param {string} mm - ë¶„
     * @param {string} ss - ì´ˆ
     * @param {string} ms - ë°€ë¦¬ì´ˆ
     * @returns {number} ë°€ë¦¬ì´ˆ
     */
    timeToMs(hh, mm, ss, ms) {
        return (
            parseInt(hh) * 3600000 +
            parseInt(mm) * 60000 +
            parseInt(ss) * 1000 +
            parseInt(ms)
        );
    }

    /**
     * ë°€ë¦¬ì´ˆë¥¼ ì‹œê°„ ë¬¸ìì—´ë¡œ ë³€í™˜
     * @param {number} ms - ë°€ë¦¬ì´ˆ
     * @returns {string} ì‹œê°„ ë¬¸ìì—´ (HH:MM:SS.mmm)
     */
    msToTime(ms) {
        const hh = Math.floor(ms / 3600000);
        const mm = Math.floor((ms % 3600000) / 60000);
        const ss = Math.floor((ms % 60000) / 1000);
        const mmm = ms % 1000;

        return `${String(hh).padStart(2, '0')}:${String(mm).padStart(2, '0')}:${String(ss).padStart(2, '0')}.${String(mmm).padStart(3, '0')}`;
    }

    /**
     * í…ìŠ¤íŠ¸ë¥¼ ìŒì„± ì‹œí€€ìŠ¤ë¡œ ë³€í™˜
     * @param {string} text - ì…ë ¥ í…ìŠ¤íŠ¸
     * @param {Object} voiceProfile - ìŒì„± í”„ë¡œí•„
     * @returns {Array} ìŒì„± ì‹œí€€ìŠ¤
     */
    textToAnimalese(text, voiceProfile) {
        return this.textProcessor.textToAnimalese(text, voiceProfile);
    }

    /**
     * í…ìŠ¤íŠ¸ë¥¼ WAVë¡œ ë³€í™˜
     * @param {string} text - ì…ë ¥ í…ìŠ¤íŠ¸
     * @param {Object} voiceProfile - ìŒì„± í”„ë¡œí•„
     * @param {string} quality - í’ˆì§ˆ ('low', 'standard', 'high')
     * @returns {Promise<Blob>} WAV Blob
     */
    async convertTextToWav(text, voiceProfile, quality = 'low') {
        console.log('\n========================================');
        console.log('=== TEXT TO WAV CONVERSION START ===');
        console.log('========================================');
        console.log('Input text:', text);
        console.log('Voice profile:', voiceProfile);
        console.log('Quality:', quality);
        console.log('ttsEngine:', this);
        console.log('Audio manager:', this.audioManager);

        if (!text || text.trim() === '') {
            throw new Error('ë³€í™˜í•  í…ìŠ¤íŠ¸ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤');
        }

        const sequence = this.textToAnimalese(text, voiceProfile);
        console.log('ìƒì„±ëœ ì‹œí€€ìŠ¤:', sequence);

        if (sequence.length === 0) {
            throw new Error('ìŒì„± ì‹œí€€ìŠ¤ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤');
        }

        // í‰ê·  rate ê³„ì‚° (atempo í•„í„°ì— ì‚¬ìš©)
        let totalRate = 0;
        sequence.forEach((sound, i) => {
            const rate = sound.rate || 1.0;
            totalRate += rate;
        });
        const avgRate = 1.0; // ffmpeg atempoë¥¼ 1ë¡œ ê³ ì •
        console.log(`ë³€í™˜ ì‹œ í‰ê·  ì¬ìƒ ì†ë„ (atempo ê°’): ${avgRate.toFixed(3)}`);

        try {
            const wavBlob = await this.waveRecorder.recordSequence(sequence, { quality, playbackRate: avgRate, voiceProfile });
            console.log('WAV ë³€í™˜ ì„±ê³µ:', wavBlob.size, 'ë°”ì´íŠ¸');
            return wavBlob;
        } catch (error) {
            console.error('WAV ë³€í™˜ ì‹¤íŒ¨:', error);
            throw new Error(`WAV ë³€í™˜ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: ${error.message}`);
        }
    }

    /**
     * ì„ íƒí•œ cueë¥¼ WAVë¡œ ë³€í™˜
     * @param {string} cueText - cue í…ìŠ¤íŠ¸
     * @param {Object} voiceProfile - ìŒì„± í”„ë¡œí•„
     * @param {string} quality - í’ˆì§ˆ
     * @returns {Promise<Blob>} WAV Blob
     */
    async convertCueToWav(cueText, voiceProfile, quality = 'low') {
        const sequence = this.textToAnimalese(cueText, voiceProfile);

        // í‰ê·  rate ê³„ì‚° (atempo í•„í„°ì— ì‚¬ìš©)
        let totalRate = 0;
        sequence.forEach((sound) => {
            const rate = sound.rate || 1.0;
            totalRate += rate;
        });
        const avgRate = 1.0; // ffmpeg atempoë¥¼ 1ë¡œ ê³ ì •
        console.log(`Cue ë³€í™˜ ì‹œ í‰ê·  ì¬ìƒ ì†ë„ (atempo ê°’): ${avgRate.toFixed(3)}`);

        return await this.waveRecorder.recordSequence(sequence, { quality, playbackRate: avgRate, voiceProfile });
    }

    /**
     * ì „ì²´ SRTë¥¼ WAVë¡œ ë³€í™˜
     * @param {string} srtContent - SRT íŒŒì¼ ë‚´ìš©
     * @param {Object} options - ì˜µì…˜ (voiceProfile, quality)
     * @returns {Promise<Blob>} WAV Blob
     */
    async convertSRTToWav(srtContent, options) {
        const cues = this.parseSRT(srtContent);
        const { voiceProfile, quality = 'low' } = options;

        const audioSegments = [];

        for (const cue of cues) {
            // ê° cue ë³€í™˜
            const sequence = this.textToAnimalese(cue.text, voiceProfile);

            // íƒ€ì„ìŠ¤íƒ¬í”„ì— ë§ì¶° ê¸¸ì´ ì¡°ì •
            const adjusted = this.adjustToDuration(sequence, cue.duration);

            audioSegments.push({
                ...adjusted,
                startTime: cue.startTime,
                endTime: cue.endTime
            });
        }

        // ì „ì²´ íƒ€ì„ë¼ì¸ í•©ì¹˜ê¸°
        return this.mergeToWav(audioSegments, quality);
    }

    /**
     * ì‹œí€€ìŠ¤ë¥¼ íƒ€ì„ìŠ¤íƒ¬í”„ì— ë§ì¶° ì¡°ì •
     * @param {Array} sequence - ìŒì„± ì‹œí€€ìŠ¤
     * @param {number} targetDuration - ëª©í‘œ ì§€ì† ì‹œê°„ (ms)
     * @returns {Array} ì¡°ì •ëœ ì‹œí€€ìŠ¤
     */
    adjustToDuration(sequence, targetDuration) {
        const currentDuration = sequence.reduce((sum, s) => sum + s.duration, 0);

        if (currentDuration === 0) return sequence;

        const ratio = targetDuration / currentDuration;

        // ì „ì²´ ê¸¸ì´ ì¡°ì • (rate ë³€ê²½ìœ¼ë¡œ)
        return sequence.map(sound => ({
            ...sound,
            duration: sound.duration * ratio,
            rate: sound.rate * ratio
        }));
    }

    /**
     * ì—¬ëŸ¬ ì˜¤ë””ì˜¤ ì„¸ê·¸ë¨¼íŠ¸ë¥¼ í•˜ë‚˜ë¡œ í•©ì¹˜ê¸°
     * @param {Array} segments - ì˜¤ë””ì˜¤ ì„¸ê·¸ë¨¼íŠ¸ ë°°ì—´
     * @param {string} quality - í’ˆì§ˆ
     * @returns {Promise<Blob>} í•©ì³ì§„ WAV Blob
     */
    async mergeToWav(segments, quality) {
        // ì „ì²´ ì‹œí€€ìŠ¤ì˜ í‰ê·  rate ê³„ì‚°
        let totalRate = 0;
        let totalSounds = 0;
        for (const segment of segments) {
            for (const sound of segment.sequence) {
                const rate = sound.rate || 1.0;
                totalRate += rate;
                totalSounds++;
            }
        }
        const avgRate = 1.0; // ffmpeg atempoë¥¼ 1ë¡œ ê³ ì •
        console.log(`SRT ì „ì²´ ë³€í™˜ ì‹œ í‰ê·  ì¬ìƒ ì†ë„ (atempo ê°’): ${avgRate.toFixed(3)}`);

        // ê° ì„¸ê·¸ë¨¼íŠ¸ë¥¼ ê°œë³„ì ìœ¼ë¡œ WAVë¡œ ë³€í™˜
        const wavBlobs = [];
        for (const segment of segments) {
            const blob = await this.waveRecorder.recordSequence(segment.sequence, { quality, playbackRate: avgRate, voiceProfile });
            wavBlobs.push({ blob, startTime: segment.startTime, endTime: segment.endTime });
        }

        // ê°€ì¥ ê¸´ ì˜¤ë””ì˜¤ë¥¼ ê¸°ì¤€ìœ¼ë¡œ í•©ì¹˜ê¸°
        const maxDuration = Math.max(...wavBlobs.map(w => w.endTime));
        return this.concatenateWavs(wavBlobs, maxDuration, quality);
    }

    /**
     * ì—¬ëŸ¬ WAVë¥¼ íƒ€ì„ë¼ì¸ì— ë§ì¶° í•©ì¹˜ê¸°
     * @param {Array} wavBlobs - WAV Blob ë°°ì—´
     * @param {number} totalDuration - ì´ ì§€ì† ì‹œê°„ (ms)
     * @param {string} quality - í’ˆì§ˆ
     * @returns {Promise<Blob>} í•©ì³ì§„ WAV Blob
     */
    async concatenateWavs(wavBlobs, totalDuration, quality) {
        // ê°„ë‹¨í•œ êµ¬í˜„: ì²« ë²ˆì§¸ WAVë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë‚˜ë¨¸ì§€ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ì—°ê²°
        // (ì‹¤ì œë¡œëŠ” íƒ€ì„ìŠ¤íƒ¬í”„ì— ë§ì¶° ì •í™•í•œ ìœ„ì¹˜ì— ë°°ì¹˜í•´ì•¼ í•¨)

        const config = this.waveRecorder.getWavConfig(quality);
        const sampleRate = config.sampleRate;
        const totalSamples = Math.floor((totalDuration / 1000) * sampleRate);

        // ë¹ˆ WAV ë²„í¼ ìƒì„±
        const audioContext = new AudioContext();
        const mergedBuffer = audioContext.createBuffer(1, totalSamples, sampleRate);
        const mergedData = mergedBuffer.getChannelData(0);

        // ê° WAVë¥¼ í•´ë‹¹ ìœ„ì¹˜ì— ë³µì‚¬
        for (const item of wavBlobs) {
            const arrayBuffer = await item.blob.arrayBuffer();
            const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);
            const channelData = audioBuffer.getChannelData(0);

            const startSample = Math.floor((item.startTime / 1000) * sampleRate);
            const endSample = Math.min(startSample + channelData.length, totalSamples);

            for (let i = startSample; i < endSample; i++) {
                if (i < totalSamples) {
                    mergedData[i] = channelData[i - startSample];
                }
            }
        }

        return this.waveRecorder.encodeWav(mergedBuffer, config);
    }

    /**
     * í…ìŠ¤íŠ¸ ë¯¸ë¦¬ë“£ê¸°
     * @param {string} text - ì…ë ¥ í…ìŠ¤íŠ¸
     * @param {Object} voiceProfile - ìŒì„± í”„ë¡œí•„
     * @returns {Promise<void>}
     */
    async preview(text, voiceProfile) {
        try {
            console.log('TTS ë¯¸ë¦¬ë“£ê¸° ì‹œì‘:', text);
            console.log('ìŒì„± í”„ë¡œí•„:', voiceProfile);

            // í…ìŠ¤íŠ¸â†’WAV ë³€í™˜ê³¼ ë™ì¼í•œ ë°©ì‹ìœ¼ë¡œ ì²˜ë¦¬
            const wavBlob = await this.convertTextToWav(text, voiceProfile, 'low');

            // WAV Blobì„ Blob URLë¡œ ë³€í™˜
            const audioUrl = URL.createObjectURL(wavBlob);

            // HTML5 Audioë¡œ ì¬ìƒ
            const audio = new Audio(audioUrl);
            audio.volume = voiceProfile.volume || 0.65;

            audio.onended = () => {
                console.log('TTS ë¯¸ë¦¬ë“£ê¸° ì™„ë£Œ');
                URL.revokeObjectURL(audioUrl);
            };

            audio.onerror = (error) => {
                console.error('ë¯¸ë¦¬ë“£ê¸° ì¬ìƒ ì˜¤ë¥˜:', error);
                URL.revokeObjectURL(audioUrl);
            };

            console.log('ë¯¸ë¦¬ë“£ê¸° WAV ì¬ìƒ ì‹œì‘');
            await audio.play();

        } catch (error) {
            console.error('ë¯¸ë¦¬ë“£ê¸° ì‹¤íŒ¨:', error);
            throw error;
        }
    }
}

// ëª¨ë“ˆ.exports
if (typeof module !== 'undefined' && module.exports) {
    module.exports = {
        TTSEngine,
        TextProcessor,
        WaveRecorder
    };
}

// ë¸Œë¼ìš°ì € ì „ì—­ì— ë…¸ì¶œ
if (typeof window !== 'undefined') {
    window.TTSEngine = TTSEngine;
    window.TextProcessor = TextProcessor;
    window.WaveRecorder = WaveRecorder;
    console.log('TTS Engine ì „ì—­ ë³€ìˆ˜ ë“±ë¡ë¨');
}
